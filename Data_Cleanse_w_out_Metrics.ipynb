{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19981f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import glob\n",
    "\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f9e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory:\n",
      "C:\\Users\\E178162\\Documents\\Work Orders\\DB\\Jupyter Notebooks\\Data Cleanse\n",
      "\n",
      "New Directory:\n",
      "C:\\Users\\E178162\\Documents\\Work Orders\\Work Order - Data\\WO_Folders\\WO_2022-2023\n",
      "\n",
      "Latest CSV Received:  Work_Order_(04_28_2023_03_54_18_PM).csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get current working directory\n",
    "def current_path():\n",
    "    print(\"Current Directory:\")\n",
    "    print(os.getcwd())\n",
    "    print()\n",
    "    \n",
    "# Function to get new directory \n",
    "def new_path():\n",
    "    print(\"New Directory:\")\n",
    "    print(os.getcwd())\n",
    "    print()\n",
    " \n",
    " \n",
    "# Driver's code\n",
    "# Printing CWD before\n",
    "current_path()\n",
    " \n",
    "# Changing the CWD\n",
    "os.chdir('../../../Work Order - Data/WO_Folders/WO_2022-2023')\n",
    " \n",
    "# Printing CWD after\n",
    "new_path()\n",
    "\n",
    "#Itererates and gets the latest file\n",
    "cwd = os.getcwd()\n",
    "files = [x for x in os.listdir(cwd) if x.endswith(\".csv\")]\n",
    "newest_file = max(files, key = os.path.getctime)\n",
    "print(\"Latest CSV Received: \", newest_file)\n",
    "\n",
    "#Ensuring that the files is chosen:\n",
    "os.path.exists(newest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc53d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'Work Order #': str}\n",
    "\n",
    "df = pd.read_csv(newest_file, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807b8f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45053 entries, 0 to 45075\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Work Order ID    45053 non-null  object \n",
      " 1   WO Status        45053 non-null  object \n",
      " 2   Priority         43169 non-null  object \n",
      " 3   Work Category    45053 non-null  object \n",
      " 4   Problem          45053 non-null  object \n",
      " 5   Source Site      45053 non-null  object \n",
      " 6   Site_ID          45053 non-null  int32  \n",
      " 7   Source Location  43394 non-null  object \n",
      " 8   Source User      45053 non-null  object \n",
      " 9   Date Open        45053 non-null  object \n",
      " 10  Date Closed      39834 non-null  object \n",
      " 11  Date Difference  45053 non-null  int64  \n",
      " 12  Duration         45053 non-null  float64\n",
      " 13  School Year      45053 non-null  object \n",
      " 14  Work Type        23979 non-null  object \n",
      " 15  Labor Hrs        45053 non-null  float64\n",
      " 16  Part Cost        45053 non-null  float64\n",
      " 17  Labor Cost       45053 non-null  float64\n",
      " 18  Total Hrs        45053 non-null  float64\n",
      " 19  Grand Total      45053 non-null  float64\n",
      " 20  Row Count        45053 non-null  int64  \n",
      "dtypes: float64(6), int32(1), int64(2), object(12)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Date Open'] = pd.to_datetime(df['Created On']).dt.date\n",
    "df['Date Closed'] = pd.to_datetime(df['Completed']).dt.date #Creates new column and sets data type from DateTime -> Date\n",
    "\n",
    "df['Date Difference'] = date.today() - df['Date Open'] #Takes the difference between today's date from Date Open\n",
    "df['Date Difference'] = df['Date Difference'].dt.days #Converts DateTime Type to Integer\n",
    "\n",
    "df['Duration'] = df['Date Closed'] - df['Date Open'] #Takes the diffrence between Date Closed from Date Open\n",
    "df['Duration'] = df['Duration'].dt.days #Converts DateTime Type to Integer\n",
    "df['Duration'] = df['Duration'].abs() #Gets the Absolute Value of Column Values\n",
    "\n",
    "df['Site_ID'] = df['Source Site'].str[-3:] #Takes the last 3 characters froms string in this case, we get extract the Site Code\n",
    "\n",
    "df['School Year'] = '2022 - 2023' #Create new column of School Year\n",
    "\n",
    "df['Duration'] = df['Duration'].fillna(df['Date Difference']) #Fill null values from Duration column with values from Date Difference\n",
    "\n",
    "df['Row Count'] = 1 #Create new column of Row Count\n",
    "\n",
    "df = df.drop(columns=['Area/Room #', 'Originator', 'Originator First Name', 'Work requested', 'Cause', 'Action Taken', 'Comments' ,'Longitude', 'Latitude', 'PM Title', 'Completed','Created On', 'Originated']) #Drops/Removes the columns from table\n",
    "\n",
    "df = df[df['Site_ID'].str.contains(\"ZZ-|032|941|ium\") == False] #Remove any string or cell that contains those characters\n",
    "\n",
    "df = df.drop_duplicates(subset='Work Order #', keep='first') #Remove any duplicates\n",
    "\n",
    "# Delete rows where work order is present but work category is null\n",
    "df = df.dropna(subset=['Work Category'])\n",
    "\n",
    "df = df.rename(columns={\"Work Order #\": \"Work Order ID\"})\n",
    "\n",
    "df\n",
    "\n",
    "columns = ['Work Order ID', 'WO Status', 'Priority', 'Work Category', 'Problem',\n",
    "              'Source Site', 'Site_ID' , 'Source Location', 'Source User', \n",
    "              'Date Open', 'Date Closed', 'Date Difference', 'Duration',\n",
    "              'School Year','Work Type', 'Labor Hrs', 'Part Cost', 'Labor Cost',\n",
    "              'Total Hrs', 'Grand Total', 'Row Count'] \n",
    "\n",
    "df = df[columns]\n",
    "\n",
    "df['Site_ID'] = df['Site_ID'].astype(int)\n",
    "\n",
    "df[\"Source User\"].fillna(\"Pending Assignment\", inplace=True)\n",
    "\n",
    "work_order_report = df\n",
    "\n",
    "work_order_report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5057e261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Work Order ID, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "null_category_wos = df.loc[df['Work Category'].isnull(), 'Work Order ID']\n",
    "print(null_category_wos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d619125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload each dataframe into separate tables\n",
    "dataframes = [work_order_report]\n",
    "table_names = [\"work_order_report\"]\n",
    "\n",
    "def clean_colname(dataframe):\n",
    "    #force column names to be lower case, no spaces, no dashes\n",
    "    dataframe.columns = [x.lower().replace(\" \", \"_\") for x in dataframe.columns]\n",
    "    \n",
    "    #processing data\n",
    "    replacements = {\n",
    "       'timedelta64[ns]': 'varchar',\n",
    "        'object': 'varchar',\n",
    "        'float64': 'float',\n",
    "        'int64': 'integer',\n",
    "        'datetime64': 'timestamp',\n",
    "        'int32': 'integer'\n",
    "    }\n",
    "\n",
    "    col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(dataframe.columns, dataframe.dtypes.replace(replacements)))\n",
    "    \n",
    "    return col_str, dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872ba2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n",
      "work_order_report was created successfully\n",
      "Data was inserted successfully\n",
      "Table work_order_report imported to db completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def upload_to_db(host, dbname, user, password, col_str, table_name, dataframe, cur):\n",
    "    conn_string = \"host={} dbname={} user={} password={}\".format(host, dbname, user, password)\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    print('Opened database successfully')\n",
    "    \n",
    "    # Drop table with same name\n",
    "    cur.execute(\"DROP TABLE IF EXISTS %s CASCADE;\" % (table_name))\n",
    "\n",
    "    # Create table\n",
    "    cur.execute(\"CREATE TABLE %s (%s);\" % (table_name, col_str))\n",
    "    print('{0} was created successfully'.format(table_name)) \n",
    "    \n",
    "    # Replace NaT values with NULL\n",
    "    dataframe = dataframe.where(pd.notnull(dataframe), None)\n",
    "\n",
    "    # Insert data into table\n",
    "    for index, row in dataframe.iterrows():\n",
    "        values = ', '.join([\"NULL\" if val is None else \"'{}'\".format(str(val).replace(\"'\", \"''\")) for val in row.tolist()])\n",
    "        cur.execute(\"INSERT INTO %s (%s) VALUES (%s);\" % (table_name, \", \".join(dataframe.columns), values))\n",
    "    print('Data was inserted successfully')\n",
    "    \n",
    "    cur.execute(\"GRANT SELECT ON TABLE %s TO public;\" % table_name)\n",
    "    \n",
    "    conn.commit()\n",
    "    print('Table {0} imported to db completed'.format(table_name))\n",
    "    print()\n",
    "    \n",
    "    return 'Upload to database completed successfully'\n",
    "\n",
    "# Create a cursor object\n",
    "conn_string = \"host=localhost dbname=AE_Work_Orders_NM user=postgres password=postgres\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Upload each dataframe into separate tables\n",
    "for i, df in enumerate(dataframes):\n",
    "    col_str, dataframe_columns = clean_colname(df)\n",
    "    table_name = table_names[i]\n",
    "    upload_to_db(\"localhost\", \"AE_Work_Orders_NM\", \"postgres\", \"postgres\", col_str, table_name, df, cur)\n",
    "\n",
    "\n",
    "# Add primary key to Table 8\n",
    "cur.execute(\"ALTER TABLE work_order_report ADD PRIMARY KEY (work_order_id)\")\n",
    "\n",
    "# Add foreign key to Table 8\n",
    "cur.execute(\"ALTER TABLE work_order_report ALTER COLUMN date_open TYPE date USING NULLIF(date_open, '')::date\")\n",
    "cur.execute(\"ALTER TABLE work_order_report ALTER COLUMN date_closed TYPE date USING NULLIF(date_closed, '')::date\")\n",
    "cur.execute(\"ALTER TABLE work_order_report ADD CONSTRAINT fk_work_category FOREIGN KEY (work_category) REFERENCES work_category(work_category)\")\n",
    "cur.execute(\"ALTER TABLE work_order_report ADD CONSTRAINT fk_site_id FOREIGN KEY (site_id) REFERENCES school_information(site_id)\")\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
